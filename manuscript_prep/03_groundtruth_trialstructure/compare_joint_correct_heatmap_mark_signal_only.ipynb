{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Hierarchical Joint Inference Results - v6\n",
    "\n",
    "**Key updates from v5:**\n",
    "1. Supports hierarchical results with `theta_X`, `theta_D` and `X_fine`, `D_fine`\n",
    "2. Added **2D scatter plots** of βR vs βI posteriors with coupling status in title\n",
    "3. Use only **|E[β]|** (norm of posterior mean) - removed biased E[|β|] comparisons\n",
    "4. Heatmaps: Only mark TRUE couplings with ★, no markers for uncoupled\n",
    "5. Log-scale W statistic heatmap to handle extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.colors import ListedColormap, LogNorm\n",
    "import matplotlib.patheffects as patheffects\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy import stats\n",
    "from simulate_trial_data import TrialSimConfig\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "project_root = \"/orcd/data/ekmiller/001/bowen/spike_field_joint_inference\"\n",
    "# add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"./data/sim_with_trials.pkl\"\n",
    "RESULTS_PATH = \"./results/joint_wald_test.pkl\"  # Updated for hierarchical\n",
    "OUTPUT_DIR = \"./figures/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "KEEP_FIRST = 0.3\n",
    "SIGNIFICANCE_THRESHOLD = 0.05\n",
    "CREDIBLE_INTERVAL = 0.95\n",
    "BURNIN_FRAC = 0.5\n",
    "THIN = 2\n",
    "\n",
    "COLOR_PERCENTILE = 99\n",
    "EFFECT_CMAP = 'Reds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate_trial_data import TrialSimConfig\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "LFP = data[\"LFP\"]\n",
    "spikes = data[\"spikes\"]\n",
    "freqs_true = np.asarray(data[\"freqs_hz\"], float)\n",
    "freqs_coupled = np.asarray(data.get(\"freqs_hz_coupled\", freqs_true), float)\n",
    "freqs_extra = np.asarray(data.get(\"freqs_hz_extra\", []), float)\n",
    "freqs_true_int = freqs_true.astype(int)\n",
    "freqs_coupled_int = freqs_coupled.astype(int)\n",
    "freqs_extra_int = freqs_extra.astype(int)\n",
    "freqs_extra_set = set(freqs_extra_int.tolist())\n",
    "masks = np.asarray(data[\"masks\"], bool)\n",
    "delta_spk = float(data.get(\"delta_spk\", 0.001))\n",
    "\n",
    "if 'beta_mag' in data:\n",
    "    beta_mag_true = np.asarray(data['beta_mag'])\n",
    "    beta_phase_true = np.asarray(data['beta_phase'])\n",
    "else:\n",
    "    beta_true = np.asarray(data[\"beta_true\"])\n",
    "    J = len(freqs_true)\n",
    "    betaR, betaI = beta_true[:, 1:1+J], beta_true[:, 1+J:1+2*J]\n",
    "    beta_mag_true = np.sqrt(betaR**2 + betaI**2)\n",
    "    beta_phase_true = np.arctan2(betaI, betaR)\n",
    "\n",
    "# Compute true βR and βI from magnitude and phase\n",
    "beta_R_true = beta_mag_true * np.cos(beta_phase_true)\n",
    "beta_I_true = beta_mag_true * np.sin(beta_phase_true)\n",
    "\n",
    "R, T = LFP.shape\n",
    "_, n_units, T_fine = spikes.shape\n",
    "J_true = len(freqs_true)\n",
    "fs = 1000.0\n",
    "\n",
    "print(f\"LFP: {LFP.shape}, Spikes: {spikes.shape}\")\n",
    "print(f\"True frequencies: {freqs_true}\")\n",
    "print(f\"Coupling mask:\\n{masks}\")\n",
    "\n",
    "print(\"\\nGround Truth |β|:\")\n",
    "for s in range(n_units):\n",
    "    coupled = [f\"{freqs_true[j]:.0f}Hz={beta_mag_true[s,j]:.3f}\" for j in range(J_true) if masks[s,j]]\n",
    "    print(f\"  Unit {s}: {', '.join(coupled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Hierarchical Joint Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "trace_beta = results['trace']['beta']\n",
    "freqs_dense = results['freqs_dense']\n",
    "B = len(freqs_dense)\n",
    "\n",
    "print(f\"Trace shape: {trace_beta.shape}\")\n",
    "print(f\"Dense freqs: {B} from {freqs_dense[0]} to {freqs_dense[-1]} Hz\")\n",
    "\n",
    "# Check for hierarchical results\n",
    "if 'theta_X' in results:\n",
    "    print(f\"\\nHierarchical model detected:\")\n",
    "    print(f\"  θ_X (shared): λ range [{results['theta_X']['lam'].min():.2f}, {results['theta_X']['lam'].max():.2f}]\")\n",
    "    print(f\"  θ_D (per-trial): λ range [{results['theta_D']['lam'].min():.2f}, {results['theta_D']['lam'].max():.2f}]\")\n",
    "    \n",
    "if 'X_fine' in results['trace']:\n",
    "    print(f\"  X_fine samples: {len(results['trace']['X_fine'])}\")\n",
    "if 'D_fine' in results['trace']:\n",
    "    print(f\"  D_fine samples: {len(results['trace']['D_fine'])}\")\n",
    "\n",
    "# Map true frequencies to dense grid indices\n",
    "idx_map = np.array([np.argmin(np.abs(freqs_dense - f)) for f in freqs_true])\n",
    "print(f\"\\nTrue freq -> Dense idx mapping:\")\n",
    "for j, f in enumerate(freqs_true):\n",
    "    print(f\"  {f:.0f} Hz -> idx {idx_map[j]} (dense={freqs_dense[idx_map[j]]:.0f} Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Posterior Statistics\n",
    "\n",
    "Using **|E[β]|** = √(E[βR]² + E[βI]²) — norm of the posterior mean (correct for significance testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply burnin and thinning\n",
    "n_samples_raw = trace_beta.shape[0]\n",
    "burnin = int(BURNIN_FRAC * n_samples_raw)\n",
    "\n",
    "postB = trace_beta[burnin::THIN]\n",
    "Nsamp = postB.shape[0]\n",
    "\n",
    "print(f\"Raw samples: {n_samples_raw}, After burnin/thin: {Nsamp}\")\n",
    "\n",
    "# Extract real and imaginary parts\n",
    "beta_R_post = postB[:, :, 1:1+B]       # (Nsamp, S, B)\n",
    "beta_I_post = postB[:, :, 1+B:1+2*B]   # (Nsamp, S, B)\n",
    "\n",
    "print(f\"β_R range: [{beta_R_post.min():.4f}, {beta_R_post.max():.4f}]\")\n",
    "print(f\"β_I range: [{beta_I_post.min():.4f}, {beta_I_post.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Posterior mean and |E[β]| (norm of mean) - CORRECT for significance testing\n",
    "# ============================================================================\n",
    "mean_R = np.mean(beta_R_post, axis=0)  # (S, B)\n",
    "mean_I = np.mean(beta_I_post, axis=0)  # (S, B)\n",
    "\n",
    "# |E[β]| = norm of posterior mean\n",
    "mag_norm_of_mean = np.sqrt(mean_R**2 + mean_I**2)  # (S, B)\n",
    "\n",
    "# Phase from posterior mean\n",
    "phase_mean = np.arctan2(mean_I, mean_R)  # (S, B)\n",
    "\n",
    "print(f\"|E[β]| range: [{mag_norm_of_mean.min():.4f}, {mag_norm_of_mean.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Wald test for H₀: β = 0\n",
    "# W = μᵀΣ⁻¹μ ~ χ²(2) under H₀\n",
    "# ============================================================================\n",
    "W_all = np.zeros((n_units, B))\n",
    "pvals_all = np.zeros((n_units, B))\n",
    "\n",
    "for s in range(n_units):\n",
    "    for j in range(B):\n",
    "        br = beta_R_post[:, s, j]\n",
    "        bi = beta_I_post[:, s, j]\n",
    "        \n",
    "        # Posterior mean\n",
    "        mu = np.array([np.mean(br), np.mean(bi)])\n",
    "        \n",
    "        # Posterior covariance\n",
    "        X = np.column_stack([br, bi])\n",
    "        Sigma = np.cov(X, rowvar=False, ddof=1)\n",
    "        \n",
    "        # Add small ridge for stability\n",
    "        Sigma = Sigma + 1e-10 * np.eye(2)\n",
    "        \n",
    "        # Wald statistic: W = μᵀΣ⁻¹μ\n",
    "        try:\n",
    "            W_all[s, j] = mu @ np.linalg.solve(Sigma, mu)\n",
    "            pvals_all[s, j] = 1 - stats.chi2.cdf(W_all[s, j], df=2)\n",
    "        except np.linalg.LinAlgError:\n",
    "            W_all[s, j] = 0.0\n",
    "            pvals_all[s, j] = 1.0\n",
    "\n",
    "print(f\"W range: [{W_all.min():.2f}, {W_all.max():.2f}]\")\n",
    "print(f\"log₁₀(W+1) range: [{np.log10(W_all.min()+1):.2f}, {np.log10(W_all.max()+1):.2f}]\")\n",
    "print(f\"p-value range: [{pvals_all.min():.2e}, {pvals_all.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FDR correction for significance (at true frequencies only for confusion matrix)\n",
    "# ============================================================================\n",
    "from scipy.stats import false_discovery_control\n",
    "\n",
    "# Significance across ALL frequencies (for heatmap)\n",
    "sig_joint = np.zeros_like(pvals_all, dtype=bool)\n",
    "for s in range(n_units):\n",
    "    pv = pvals_all[s]\n",
    "    # BH-FDR correction\n",
    "    adjusted_pv = false_discovery_control(pv, method='bh')\n",
    "    reject = adjusted_pv <= SIGNIFICANCE_THRESHOLD\n",
    "    sig_joint[s] = reject\n",
    "\n",
    "# Extract significance at TRUE frequencies\n",
    "sig_at_true = sig_joint[:, idx_map]  # (S, J_true)\n",
    "\n",
    "print(f\"Significant bands per unit: {sig_joint.sum(axis=1)}\")\n",
    "print(f\"Significant at true frequencies: {sig_at_true.sum()} / {n_units * J_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detection Metrics at True Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Compute TP/FP/TN/FN at TRUE frequencies\n",
    "# ============================================================================\n",
    "TP = np.sum(sig_at_true & masks)\n",
    "FN = np.sum(~sig_at_true & masks)\n",
    "FP = np.sum(sig_at_true & ~masks)\n",
    "TN = np.sum(~sig_at_true & ~masks)\n",
    "\n",
    "n_coupled = masks.sum()\n",
    "n_uncoupled = (~masks).sum()\n",
    "\n",
    "sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "\n",
    "print(\"Confusion Matrix at TRUE frequencies:\")\n",
    "print(f\"              Detected   Not Detected\")\n",
    "print(f\"  Coupled        {TP:3d}         {FN:3d}      (total: {n_coupled})\")\n",
    "print(f\"  Not Coupled    {FP:3d}         {TN:3d}      (total: {n_uncoupled})\")\n",
    "print(f\"\\n  Sensitivity (TP rate): {sensitivity:.1%} ({TP}/{TP+FN})\")\n",
    "print(f\"  Specificity (TN rate): {specificity:.1%} ({TN}/{TN+FP})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed breakdown\n",
    "print(\"\\nDetailed breakdown at TRUE frequencies:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract at true frequencies\n",
    "mag_at_true = mag_norm_of_mean[:, idx_map]  # |E[β]|\n",
    "W_at_true = W_all[:, idx_map]\n",
    "pvals_at_true = pvals_all[:, idx_map]\n",
    "phase_at_true = phase_mean[:, idx_map]\n",
    "\n",
    "for s in range(n_units):\n",
    "    print(f\"\\nUnit {s}:\")\n",
    "    for j, f in enumerate(freqs_true):\n",
    "        coupled = masks[s, j]\n",
    "        sig = sig_at_true[s, j]\n",
    "        W_val = W_at_true[s, j]\n",
    "        mag_val = mag_at_true[s, j]\n",
    "        p_val = pvals_at_true[s, j]\n",
    "        \n",
    "        if coupled and sig:\n",
    "            status = \"TP ✓\"\n",
    "        elif coupled and not sig:\n",
    "            status = \"FN ✗\"\n",
    "        elif not coupled and sig:\n",
    "            status = \"FP ✗\"\n",
    "        else:\n",
    "            status = \"TN ✓\"\n",
    "        \n",
    "        coupled_str = \"COUPLED\" if coupled else \"------\"\n",
    "        sig_str = \"SIG\" if sig else \"---\"\n",
    "        \n",
    "        print(f\"  {f:5.0f}Hz: {coupled_str} {sig_str} | W={W_val:8.1f} | p={p_val:.2e} | |E[β]|={mag_val:.4f} | {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 2D Scatter Plots: βR vs βI Posterior Samples\n",
    "\n",
    "For each unit and TRUE frequency, plot the posterior samples of (βR, βI).\n",
    "Title indicates whether this is a **Coupled** or **Uncoupled** pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beta_posterior_scatter(beta_R_samples, beta_I_samples, coupled, freq_hz, unit_idx, ax, signal_only=False):\n",
    "    \"\"\"\n",
    "    Plot 2D scatter of βR vs βI posterior samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    beta_R_samples : (N,) array of βR samples\n",
    "    beta_I_samples : (N,) array of βI samples  \n",
    "    coupled : bool - whether this is a coupled pair\n",
    "    freq_hz : frequency in Hz\n",
    "    unit_idx : unit index\n",
    "    ax : matplotlib axes\n",
    "    \"\"\"\n",
    "    # Posterior mean\n",
    "    mean_R = np.mean(beta_R_samples)\n",
    "    mean_I = np.mean(beta_I_samples)\n",
    "    \n",
    "    # Plot samples\n",
    "    ax.scatter(beta_R_samples, beta_I_samples, alpha=0.3, s=10, c='tab:blue')\n",
    "    \n",
    "    # Plot posterior mean\n",
    "    ax.scatter([mean_R], [mean_I], c='red', s=100, marker='x', linewidths=2, \n",
    "               label=f'E[β]', zorder=10)\n",
    "    \n",
    "    # Add origin\n",
    "    ax.axhline(0, color='gray', linestyle='--', alpha=0.5, linewidth=0.5)\n",
    "    ax.axvline(0, color='gray', linestyle='--', alpha=0.5, linewidth=0.5)\n",
    "    \n",
    "    # Compute 95% confidence ellipse\n",
    "    cov = np.cov(beta_R_samples, beta_I_samples)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "    order = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues, eigenvectors = eigenvalues[order], eigenvectors[:, order]\n",
    "    \n",
    "    # Chi-squared value for 95% confidence with 2 DOF\n",
    "    chi2_val = stats.chi2.ppf(0.95, 2)\n",
    "    width, height = 2 * np.sqrt(eigenvalues * chi2_val)\n",
    "    angle = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))\n",
    "    \n",
    "    ellipse = Ellipse((mean_R, mean_I), width, height, angle=angle,\n",
    "                      fill=False, color='red', linestyle='-', linewidth=1.5,\n",
    "                      label='95% CI')\n",
    "    ax.add_patch(ellipse)\n",
    "    \n",
    "    # Title with coupling status\n",
    "    if coupled:\n",
    "        status = 'Coupled'\n",
    "    else:\n",
    "        status = 'Signal-only' if signal_only else 'Uncoupled'\n",
    "    ax.set_title(f'Unit {unit_idx}, {freq_hz:.0f} Hz\\n({status})', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('βR')\n",
    "    ax.set_ylabel('βI')\n",
    "    ax.set_aspect('equal', adjustable='datalim')\n",
    "    ax.legend(fontsize=8, loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of scatter plots for all unit-frequency pairs at TRUE frequencies\n",
    "fig, axes = plt.subplots(n_units, J_true, figsize=(3.5*J_true, 3.5*n_units))\n",
    "\n",
    "for s in range(n_units):\n",
    "    for j, f in enumerate(freqs_true):\n",
    "        ax = axes[s, j] if n_units > 1 else axes[j]\n",
    "        \n",
    "        # Get dense grid index\n",
    "        j_dense = idx_map[j]\n",
    "        \n",
    "        # Get posterior samples\n",
    "        br = beta_R_post[:, s, j_dense]\n",
    "        bi = beta_I_post[:, s, j_dense]\n",
    "        \n",
    "        # Is this coupled?\n",
    "        coupled = masks[s, j]\n",
    "        \n",
    "        signal_only = (int(f) in freqs_extra_set)\n",
    "        plot_beta_posterior_scatter(br, bi, coupled, f, s, ax, signal_only=signal_only)\n",
    "        \n",
    "        # Make the origin more salient by plotting a big marker there\n",
    "        ax.scatter([0], [0], s=200, c='black', marker='o', edgecolors='white', linewidths=2, zorder=11, label='_Origin')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/beta_posterior_scatter_grid.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved to {OUTPUT_DIR}/beta_posterior_scatter_grid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate plots: Coupled vs Uncoupled\n",
    "coupled_pairs = [(s, j, freqs_true[j]) for s in range(n_units) for j in range(J_true) if masks[s, j]]\n",
    "uncoupled_pairs = [(s, j, freqs_true[j]) for s in range(n_units) for j in range(J_true) if not masks[s, j]]\n",
    "\n",
    "print(f\"Coupled pairs: {len(coupled_pairs)}\")\n",
    "print(f\"Uncoupled pairs: {len(uncoupled_pairs)}\")\n",
    "\n",
    "# Plot coupled pairs\n",
    "n_coupled = len(coupled_pairs)\n",
    "n_cols = min(5, n_coupled)\n",
    "n_rows = int(np.ceil(n_coupled / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5*n_cols, 3.5*n_rows))\n",
    "axes = np.atleast_2d(axes)\n",
    "\n",
    "for idx, (s, j, f) in enumerate(coupled_pairs):\n",
    "    row, col = idx // n_cols, idx % n_cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    j_dense = idx_map[j]\n",
    "    br = beta_R_post[:, s, j_dense]\n",
    "    bi = beta_I_post[:, s, j_dense]\n",
    "    \n",
    "    plot_beta_posterior_scatter(br, bi, True, f, s, ax)\n",
    "\n",
    "# Hide unused axes\n",
    "for idx in range(n_coupled, n_rows * n_cols):\n",
    "    row, col = idx // n_cols, idx % n_cols\n",
    "    axes[row, col].set_visible(False)\n",
    "\n",
    "plt.suptitle('Coupled Pairs: βR vs βI Posterior', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/beta_posterior_scatter_coupled.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot uncoupled pairs\n",
    "n_uncoupled = len(uncoupled_pairs)\n",
    "if n_uncoupled > 0:\n",
    "    n_cols = min(5, n_uncoupled)\n",
    "    n_rows = int(np.ceil(n_uncoupled / n_cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5*n_cols, 3.5*n_rows))\n",
    "    if n_uncoupled == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif n_rows == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "    \n",
    "    for idx, (s, j, f) in enumerate(uncoupled_pairs):\n",
    "        row, col = idx // n_cols, idx % n_cols\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        j_dense = idx_map[j]\n",
    "        br = beta_R_post[:, s, j_dense]\n",
    "        bi = beta_I_post[:, s, j_dense]\n",
    "        \n",
    "        signal_only = (int(f) in freqs_extra_set)\n",
    "        plot_beta_posterior_scatter(br, bi, False, f, s, ax, signal_only=signal_only)\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for idx in range(n_uncoupled, n_rows * n_cols):\n",
    "        row, col = idx // n_cols, idx % n_cols\n",
    "        axes[row, col].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Uncoupled Pairs: βR vs βI Posterior', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/beta_posterior_scatter_uncoupled.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_effect_heatmap(values, freqs, title, true_freqs=None, masks=None, coupled_freqs=freqs_coupled, extra_freqs=freqs_extra, \n",
    "                        log_scale=False, cmap='Reds'):\n",
    "    \"\"\"Plot heatmap with ★ markers ONLY at true coupled frequencies.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 3), \n",
    "                              gridspec_kw={'width_ratios': [20, 1]})\n",
    "    \n",
    "    if log_scale:\n",
    "        plot_values = np.log10(values + 1)\n",
    "        vmax = np.percentile(plot_values[np.isfinite(plot_values)], COLOR_PERCENTILE)\n",
    "        cbar_label = 'log₁₀(W + 1)'\n",
    "    else:\n",
    "        plot_values = values\n",
    "        vmax = np.percentile(plot_values[np.isfinite(plot_values)], COLOR_PERCENTILE)\n",
    "        cbar_label = title\n",
    "    \n",
    "    im = axes[0].imshow(plot_values, aspect='auto', cmap=cmap, \n",
    "                        vmin=0, vmax=vmax,\n",
    "                        extent=[freqs[0], freqs[-1], values.shape[0]-0.5, -0.5])\n",
    "\n",
    "    # Mark signal-only bands (no spike coupling) as dotted vertical lines\n",
    "    if extra_freqs is not None and len(extra_freqs) > 0:\n",
    "        for f in extra_freqs:\n",
    "            axes[0].axvline(float(f), color='black', linestyle=':', linewidth=1.0, alpha=0.6)\n",
    "        axes[0].text(0.99, 1.02, 'dotted: signal-only', transform=axes[0].transAxes,\n",
    "                     ha='right', va='bottom', fontsize=8)\n",
    "    \n",
    "    # Add ★ only at TRUE coupled frequencies\n",
    "    if true_freqs is not None and masks is not None:\n",
    "        idx_map_local = [np.argmin(np.abs(freqs - f)) for f in true_freqs]\n",
    "        for s in range(masks.shape[0]):\n",
    "            for j_true, j_dense in enumerate(idx_map_local):\n",
    "                if masks[s, j_true]:  # Only mark coupled\n",
    "                    freq_x = freqs[j_dense]\n",
    "                    axes[0].text(freq_x, s, '★', fontsize=12, \n",
    "                                 ha='center', va='center', color='white',\n",
    "                                 path_effects=[patheffects.withStroke(linewidth=2, foreground='black')])\n",
    "    \n",
    "    axes[0].set_xlabel('Frequency (Hz)')\n",
    "    axes[0].set_ylabel('Unit')\n",
    "    axes[0].set_title(title)\n",
    "    axes[0].set_yticks(range(values.shape[0]))\n",
    "    \n",
    "    plt.colorbar(im, cax=axes[1], label=cbar_label)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |E[β]| heatmap\n",
    "fig = plot_effect_heatmap(mag_norm_of_mean, freqs_dense, '|E[β]| (norm of posterior mean)',\n",
    "                          true_freqs=freqs_true, masks=masks)\n",
    "plt.savefig(f'{OUTPUT_DIR}/heatmap_mag_norm_mean.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W statistic heatmap (log scale)\n",
    "fig = plot_effect_heatmap(W_all, freqs_dense, 'Wald statistic (W)',\n",
    "                          true_freqs=freqs_true, masks=masks, log_scale=True)\n",
    "plt.savefig(f'{OUTPUT_DIR}/heatmap_W_statistic.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ROC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# At TRUE frequencies only\n",
    "W_true = W_all[:, idx_map].flatten()\n",
    "mag_true = mag_norm_of_mean[:, idx_map].flatten()\n",
    "labels_true = masks.flatten().astype(int)\n",
    "\n",
    "# ROC for W statistic\n",
    "fpr_W, tpr_W, _ = roc_curve(labels_true, W_true)\n",
    "auc_W = auc(fpr_W, tpr_W)\n",
    "\n",
    "# ROC for |E[β]|\n",
    "fpr_mag, tpr_mag, _ = roc_curve(labels_true, mag_true)\n",
    "auc_mag = auc(fpr_mag, tpr_mag)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(fpr_W, tpr_W, label=f'W statistic (AUC={auc_W:.3f})', lw=2)\n",
    "ax.plot(fpr_mag, tpr_mag, label=f'|E[β]| (AUC={auc_mag:.3f})', lw=2)\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve (at TRUE frequencies)')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/roc_curve.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC (W statistic): {auc_W:.3f}\")\n",
    "print(f\"AUC (|E[β]|): {auc_mag:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Magnitude Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At coupled frequencies only\n",
    "true_mags = beta_mag_true[masks]\n",
    "inferred_mags = mag_at_true[masks]\n",
    "\n",
    "# Correlation\n",
    "r = np.corrcoef(true_mags, inferred_mags)[0, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.scatter(true_mags, inferred_mags, s=60, alpha=0.7)\n",
    "\n",
    "# Fit line\n",
    "if len(true_mags) > 1:\n",
    "    z = np.polyfit(true_mags, inferred_mags, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(true_mags.min(), true_mags.max(), 100)\n",
    "    ax.plot(x_line, p(x_line), 'r--', label=f'Fit: y = {z[0]:.3f}x + {z[1]:.4f}')\n",
    "\n",
    "ax.set_xlabel('True |β|')\n",
    "ax.set_ylabel('Inferred |E[β]|')\n",
    "ax.set_title(f'Magnitude Recovery (coupled only)\\nr = {r:.3f}')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/magnitude_correlation.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Phase Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect phase data for coupled pairs\n",
    "phase_data = []\n",
    "for s in range(n_units):\n",
    "    for j in range(J_true):\n",
    "        if masks[s, j]:\n",
    "            phase_data.append({\n",
    "                'unit': s,\n",
    "                'freq': freqs_true[j],\n",
    "                'true': beta_phase_true[s, j],\n",
    "                'inferred': phase_at_true[s, j],\n",
    "            })\n",
    "\n",
    "true_phases = np.array([d['true'] for d in phase_data])\n",
    "inferred_phases = np.array([d['inferred'] for d in phase_data])\n",
    "\n",
    "# Circular error\n",
    "phase_errors = np.angle(np.exp(1j * (inferred_phases - true_phases)))\n",
    "mean_error = np.angle(np.mean(np.exp(1j * phase_errors)))\n",
    "std_error = np.sqrt(-2 * np.log(np.abs(np.mean(np.exp(1j * phase_errors)))))\n",
    "mae = np.mean(np.abs(phase_errors))\n",
    "\n",
    "print(f\"Phase error statistics (coupled only):\")\n",
    "print(f\"  Mean circular error: {np.degrees(mean_error):.1f}°\")\n",
    "print(f\"  Circular std: {np.degrees(std_error):.1f}°\")\n",
    "print(f\"  Mean absolute error: {np.degrees(mae):.1f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Panel 1: Polar plot\n",
    "ax = plt.subplot(131, projection='polar')\n",
    "for d in phase_data:\n",
    "    ax.plot([0, d['true']], [0, 0.6], 'g--', alpha=0.5, lw=1)\n",
    "    ax.plot([0, d['inferred']], [0, 0.8], 'b-', alpha=0.7, lw=2)\n",
    "\n",
    "ax.set_ylim([0, 1.2])\n",
    "ax.set_title('Phase: True (green--) vs Inferred (blue—)')\n",
    "\n",
    "# Panel 2: Phase error histogram\n",
    "ax = axes[1]\n",
    "ax.hist(np.degrees(phase_errors), bins=20, edgecolor='black', alpha=0.7, color='tab:blue')\n",
    "ax.axvline(0, color='black', linestyle='--', lw=2, label='Perfect')\n",
    "ax.axvline(np.degrees(mean_error), color='red', linestyle='-', lw=2, \n",
    "           label=f'Mean = {np.degrees(mean_error):.1f}°')\n",
    "ax.set_xlabel('Phase error (degrees)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title(f'Phase Error Distribution\\nMAE = {np.degrees(mae):.1f}°')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Panel 3: True vs Inferred phase (scatter with identity line)\n",
    "ax = axes[2]\n",
    "ax.scatter(np.degrees(true_phases), np.degrees(inferred_phases), \n",
    "           c='tab:blue', s=80, alpha=0.7)\n",
    "ax.plot([-180, 180], [-180, 180], 'k--', alpha=0.5, label='Identity')\n",
    "\n",
    "for d in phase_data:\n",
    "    ax.annotate(f'U{d[\"unit\"]},{int(d[\"freq\"])}', \n",
    "                (np.degrees(d['true']), np.degrees(d['inferred'])),\n",
    "                fontsize=7, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('True phase (degrees)')\n",
    "ax.set_ylabel('Inferred phase (degrees)')\n",
    "ax.set_title('Phase: True vs Inferred (coupled only)')\n",
    "ax.set_xlim([-180, 180])\n",
    "ax.set_ylim([-180, 180])\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/phase_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nData: {n_units} units, {J_true} true frequencies\")\n",
    "print(f\"  Coupled pairs: {masks.sum()}, Uncoupled pairs: {(~masks).sum()}\")\n",
    "print(f\"  Posterior samples: {Nsamp} (after burnin/thinning)\")\n",
    "\n",
    "print(f\"\\n--- Detection (at TRUE frequencies) ---\")\n",
    "print(f\"  Confusion matrix: TP={TP}, FN={FN}, FP={FP}, TN={TN}\")\n",
    "print(f\"  Sensitivity: {sensitivity:.1%}\")\n",
    "print(f\"  Specificity: {specificity:.1%}\")\n",
    "\n",
    "print(f\"\\n--- Ranking (ROC AUC) ---\")\n",
    "print(f\"  W statistic: {auc_W:.3f}\")\n",
    "print(f\"  |E[β]|:      {auc_mag:.3f}\")\n",
    "\n",
    "print(f\"\\n--- Magnitude Recovery (coupled only) ---\")\n",
    "print(f\"  Correlation with true |β|: r = {r:.3f}\")\n",
    "print(f\"  Mean |E[β]| coupled:   {mag_at_true[masks].mean():.4f} ± {mag_at_true[masks].std():.4f}\")\n",
    "print(f\"  Mean |E[β]| uncoupled: {mag_at_true[~masks].mean():.4f} ± {mag_at_true[~masks].std():.4f}\")\n",
    "\n",
    "print(f\"\\n--- Phase Recovery (coupled only) ---\")\n",
    "print(f\"  Mean circular error: {np.degrees(mean_error):.1f}°\")\n",
    "print(f\"  Mean absolute error: {np.degrees(mae):.1f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_out = {\n",
    "    'freqs_true': freqs_true,\n",
    "    'freqs_dense': freqs_dense,\n",
    "    'masks': masks,\n",
    "    'beta_mag_true': beta_mag_true,\n",
    "    'beta_phase_true': beta_phase_true,\n",
    "    \n",
    "    # Inferred values\n",
    "    'mag_norm_of_mean': mag_norm_of_mean,\n",
    "    'phase_mean': phase_mean,\n",
    "    'mean_R': mean_R,\n",
    "    'mean_I': mean_I,\n",
    "    \n",
    "    # Statistics\n",
    "    'W_all': W_all,\n",
    "    'pvals_all': pvals_all,\n",
    "    'sig_joint': sig_joint,\n",
    "    \n",
    "    # Metrics\n",
    "    'detection': {\n",
    "        'TP': TP, 'FN': FN, 'FP': FP, 'TN': TN,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "    },\n",
    "    'auc': {\n",
    "        'W': auc_W,\n",
    "        'mag': auc_mag,\n",
    "    },\n",
    "    'magnitude_correlation': r,\n",
    "    'phase_error': {\n",
    "        'mean_circular': mean_error,\n",
    "        'std_circular': std_error,\n",
    "        'mae': mae,\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/comparison_results_v6.pkl', 'wb') as f:\n",
    "    pickle.dump(results_out, f)\n",
    "print(f\"Results saved to {OUTPUT_DIR}/comparison_results_v6.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
